{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNSF Review Classification: Fine-tuned Hugging Face Models\n",
    "\n",
    "- Gabriel Okasa, Data Team, Swiss National Science Foundation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outline:\n",
    "\n",
    "1) load text data from a grant peer review report\n",
    "\n",
    "2) pre-process the texts for transformer model: english texts, lower casing, sentence segmentation, tokenization\n",
    "\n",
    "3) apply fine-tuned transformer models from [HuggingFace](https://huggingface.co/snsf-data) and classify sentences\n",
    "\n",
    "4) aggregate the classified categories onto a review level\n",
    "\n",
    "5) compute the shares of each classified category in a review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Imports\n",
    "\n",
    "First, we import the neccessary libraries for data wrangling and natural language processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import standard libraries\n",
    "import os\n",
    "import platform\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import pytorch and transformers with the relevant functions\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TextClassificationPipeline\n",
    "\n",
    "# import text processing and lanuage detection\n",
    "import re\n",
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup GPU for faster computing\n",
    "\n",
    "Running deep learning models, such as the transformer models in this notebook, is more efficient using a GPU unit. Below we check for the availability of a GPU unit and set it as a primary device to perform the computations if available. Note, that for running PyTorch on a GPU, you must first install the CUDA toolkit: https://docs.nvidia.com/cuda/ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use GPU if available\n",
    "current_os = platform.system()\n",
    "# active device based on OS\n",
    "if current_os == 'Darwin':\n",
    "    # specify device as mps for Mac\n",
    "    device = 'mps'\n",
    "    print('MPS will be used as a device.')\n",
    "else:\n",
    "    # check if gpu is available, if yes use cuda, if not stick to cpu\n",
    "    # install CUDA here:https://pytorch.org/get-started/locally/\n",
    "    if torch.cuda.is_available():\n",
    "        # must be 'cuda:0', not just 'cuda', see: https://github.com/deepset-ai/haystack/issues/3160\n",
    "        device = torch.device('cuda:0')\n",
    "        print('GPU', torch.cuda.get_device_name(0) ,'is available and will be used as a device.')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "        print('No GPU available, CPU will be used as a device instead.'\n",
    "              + 'Be aware that the computation time increases significantly.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import and Pre-Processing\n",
    "\n",
    "For the demonstration purposes and due to data privacy laws, we will use a fake AI-generated grant peer review report as an example. The following prompt to ChatGPT has been used to generate a fake example review:\n",
    "\n",
    "'You are a scientific expert in economics and have been requested by the Swiss National Science Foundation (SNSF) to review a grant proposal on the topic of causal inference in economics. Please, write a concise grant peer review report reflecting on the following SNSF's evaluation criteria: scientific relevance, topicality and originality; suitability of methods and feasibility; applicants' scientific track record and expertise. For each of the criteria, provide your assessment of strengths and weaknesses and a general comment. Please, provide the report in plain text. Thank you.'\n",
    "\n",
    "The AI-generated report is provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_text = \"\"\"\n",
    "\n",
    "1. Scientific Relevance, Topicality and Originality\n",
    "\n",
    "Strengths:\n",
    "The proposal addresses a highly relevant topic in contemporary economics: causal inference in observational settings, with applications to policy evaluation. The research questions are well-defined and pertinent to current empirical challenges, particularly in microeconometrics and applied public economics. The proposal demonstrates awareness of recent advances, including machine learning integration into causal analysis, and lies at the intersection of economic theory and statistical innovation.\n",
    "\n",
    "Weaknesses:\n",
    "While the research questions are timely, parts of the proposal could further clarify the added value over existing approaches. Some stated contributions—such as improving robustness in difference-in-differences designs—are valuable but incremental, and the proposal would benefit from clearer articulation of novel theoretical insights or methodological leaps.\n",
    "\n",
    "General Comment:\n",
    "The proposal is of solid scientific relevance and topicality. It engages with ongoing developments in causal inference and seeks to contribute to applied economic analysis. Originality is moderate but acceptable given the empirical ambition and interdisciplinary approach.\n",
    "\n",
    "2. Suitability of Methods and Feasibility\n",
    "\n",
    "Strengths:\n",
    "The proposed methodology is rigorous and appropriate for the stated objectives. The use of quasi-experimental designs, high-dimensional covariate control via machine learning, and sensitivity analyses demonstrates strong methodological awareness. The proposal also includes a realistic data access and management plan, which adds to feasibility.\n",
    "\n",
    "Weaknesses:\n",
    "The proposal could benefit from a more detailed discussion of potential identification challenges and how alternative specifications or falsification tests will be employed. There is also limited discussion on potential data limitations or ethical considerations in handling administrative microdata.\n",
    "\n",
    "General Comment:\n",
    "The methodological framework is sound and the proposed analysis plan is feasible within the timeline. A more comprehensive risk assessment would strengthen confidence in the empirical execution.\n",
    "\n",
    "3. Applicants' Scientific Track Record and Expertise\n",
    "\n",
    "Strengths:\n",
    "The principal investigator (PI) has a strong publication record with many publications with high impact factor in top-tier journals in applied economics and econometrics. The PI has demonstrated prior success in projects involving causal inference and is well integrated in relevant research networks. Co-investigators and collaborators also bring complementary skills in statistics and computation.\n",
    "\n",
    "Weaknesses:\n",
    "The proposal would benefit from clearer delineation of roles among team members, particularly junior researchers, and how their expertise contributes to the project's success. In addition, evidence of prior experience managing large empirical projects could be elaborated.\n",
    "\n",
    "General Comment:\n",
    "The applicants have an excellent track record and relevant expertise, providing high confidence in their ability to deliver the proposed research.\n",
    "\n",
    "Overall Assessment\n",
    "\n",
    "This is a strong proposal that addresses an important and topical area in economics. The methods are robust and appropriate, the research team is highly competent, and the proposal is feasible as presented. Some improvements could be made in terms of clarifying the originality of the theoretical contribution and expanding the discussion on identification challenges. Nonetheless, the proposal is well-positioned to make a valuable contribution to the field of causal inference in economics.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the generated example review, we proceed with text pre-processing as follows: we remove headers, section titles, special characters and trailing spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove headers and section titles\n",
    "review_text = re.sub(r'\\d+\\.\\s+[^\\n]+', '', review_text)  # Matches lines as \"1. Something\"\n",
    "review_text = re.sub(r'(Strengths:|Weaknesses:|General Comment:|Overall Assessment|)', '', review_text, flags=re.IGNORECASE)\n",
    "\n",
    "# and remove special characters\n",
    "review_text = review_text.replace('\\n', ' ')  # Replace line breaks with space\n",
    "review_text = review_text.replace('\\t', ' ')  # Replace tabs with space\n",
    "review_text = re.sub(r'\\s+', ' ', review_text)  # Collapse multiple spaces into one\n",
    "review_text = review_text.strip()  # Remove leading/trailing whitespace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we check that the review is written in English and proceed with lower-casing the text and segmenting it by sentence. This is important as the classification models were fine-tuned on a sentence level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect language of the review\n",
    "assert detect(review_text) == \"en\", \"The review is not in English, models cannot be used.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split review onto sentence level using regular expressions by sentence-ending punctuation followed by a space and a capital letter\n",
    "review_sentences = re.split(r'(?<=[.!?])\\s+(?=[A-Z])', review_text)\n",
    "# and lower-case the sentences\n",
    "review_sentences = [sentence_idx.lower() for sentence_idx in review_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the text inputs are ready to be fed into the classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Tokenizer and Models\n",
    "\n",
    "The base model for the SNSF fine-tuned models is [SPECTER2](https://huggingface.co/allenai/specter2_base) (Cohan et al., 2019), so we directly load the tokenizer of the base model from HuggingFace (Wolf et al., 2019)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tokenizer from specter2_base - the base model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/specter2_base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now load the open-sourced fine-tuned models from the SNSF's [HuggingFace](https://huggingface.co/snsf-data) account. Specifically, we will load all models, but the one classifying 'Rationale' as it's classification accuracy was notably low. Therefore any deployment should be approached with caution and thorough consideration. For details on the models' accuracy and fine-tuning procedure, please refer to the respective model cards on HuggingFace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the names for the models to be applied in a dictionary\n",
    "model_names = {'Track record': 'snsf-data/specter2-review-track-record',\n",
    "               'Relevance, originality, topicality': 'snsf-data/specter2-review-relevance-originality-topicality',\n",
    "               'Suitability': 'snsf-data/specter2-review-suitability',\n",
    "               'Feasibility': 'snsf-data/specter2-review-feasibility',\n",
    "               'Applicant': 'snsf-data/specter2-review-applicant',\n",
    "               'Applicant Quantity': 'snsf-data/specter2-review-applicant-quantity',\n",
    "               'Proposal': 'snsf-data/specter2-review-proposal',\n",
    "               'Method': 'snsf-data/specter2-review-method',\n",
    "               'Positive': 'snsf-data/specter2-review-positive',\n",
    "               'Negative': 'snsf-data/specter2-review-negative',\n",
    "               'Suggestion': 'snsf-data/specter2-review-suggestion'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify Review Sentences\n",
    "\n",
    "Below, we apply the models in a loop to classify each sentence of the review report into the given categories that the models were fine-tuned for. We save the results in a dataframe, where each column indicates if the given category is present (True) or absent (False)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate storage as an empty dictionary\n",
    "review_classified = {}\n",
    "# start the loop for each model\n",
    "for model_name_idx, model_idx in model_names.items():\n",
    "\n",
    "    # print the progress\n",
    "    print('Currently applying ' + model_name_idx + ' model for classification.\\n')\n",
    "\n",
    "    # load the SNSF fine-tuned model for classification of review texts\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_idx).to(device)\n",
    "    # setup the classification pipeline\n",
    "    classification_pipeline = TextClassificationPipeline(model=model, tokenizer=tokenizer)\n",
    "    # feed in the review sentences\n",
    "    review_sentences_classified = classification_pipeline(review_sentences)\n",
    "    # and post-process the results: as dataframe and boolean\n",
    "    review_classified[model_name_idx] = pd.DataFrame(review_sentences_classified)['label'] == 'yes'\n",
    "\n",
    "# save as dataframe\n",
    "review_classified = pd.DataFrame(review_classified)\n",
    "# and prepend sentences\n",
    "review_classified.insert(0, 'Sentence', review_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "Below, we inspect the raw classification results on a sentence level and aggregate them to represent prevalence of each category within the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the results\n",
    "review_classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the prevalences for the given review\n",
    "review_classified_prevalence = review_classified.mean(numeric_only=True)\n",
    "print(review_classified_prevalence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the results\n",
    "plt.figure(figsize=(8, 5))\n",
    "review_classified_prevalence.plot(kind='bar', color='skyblue')\n",
    "# Add descriptions\n",
    "plt.ylabel('Prevalence in %')\n",
    "plt.title('Prevalence of classified categories in a review')\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(rotation=75)\n",
    "plt.tight_layout()\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "- SNSF's fine-tuned models can be accessed and loaded directly from the [HuggingFace](https://huggingface.co/snsf-data) hub.\n",
    "- Models can be applied directly to a text data from review reports to classify review text to given categories relevant to research funders.\n",
    "- Classification results provide an aggregate overview of the contents of the grant peer review report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cohan, A., Feldman, S., Beltagy, I., Downey, D., & Weld, D. S. (2020). Specter: Document-level representation learning using citation-informed transformers. arXiv preprint arXiv:2004.07180.\n",
    "- Okasa, G., de León, A., Strinzel, M., Jorstad, A., Milzow, K., Egger, M., & Müller, S. (2024). A Supervised Machine Learning Approach for Assessing Grant Peer Review Reports. arXiv preprint arXiv:2411.16662.\n",
    "- Wolf, T., Debut, L., Sanh, V., Chaumond, J., Delangue, C., Moi, A., ... & Rush, A. M. (2019). Huggingface's transformers: State-of-the-art natural language processing. arXiv preprint arXiv:1910.03771."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
